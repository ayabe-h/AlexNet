{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\"\"\"Model\"\"\"\n",
    "class Model(nn.Module):\n",
    "    \"\"\"コンストラクタ\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        num_classes = 10\n",
    "        # 特徴量抽出\n",
    "        self.__features=nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # 分類器\n",
    "        self.__classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 4 * 4, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 4 * 4)\n",
    "        x = self.__classifier(x)\n",
    "        return x\n",
    "    \n",
    "    \"\"\"特徴量\"\"\"\n",
    "    def features(self, x):\n",
    "        x=self.__features(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn  as nn\n",
    "\n",
    "\n",
    "\"\"\"AlexNet\"\"\"\n",
    "class AlexNet(object):\n",
    "    \"\"\"コンストラクタ\"\"\"\n",
    "    def __init__(self, mode=False, model_path=''):\n",
    "        # デバイス設定 GPU or CPU\n",
    "        self.__device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        # モデル定義\n",
    "        self.__model=Model().to(self.__device)\n",
    "\n",
    "        if mode:\n",
    "            # 学習済みモデル読み込み\n",
    "            self.__model.load_state_dict(torch.load(model_path))\n",
    "            self.__model.eval()\n",
    "\n",
    "        # 学習係数\n",
    "        self.__lr=1e-3\n",
    "        # 損失関数:交差エントロピー\n",
    "        self.__loss_func=nn.CrossEntropyLoss()\n",
    "        # 最適化アルゴリズム:SGD\n",
    "        self.__opt=torch.optim.SGD(self.__model.parameters(), lr=self.__lr)\n",
    "\n",
    "        # save file path\n",
    "        self.FILE_PATH=os.path.join('./model')\n",
    "\n",
    "        # フォルダを生成\n",
    "        if not os.path.exists(self.FILE_PATH):\n",
    "            os.mkdir(self.FILE_PATH)\n",
    "\n",
    "        # 損失値格納用変数\n",
    "        self.__loss_history=[]\n",
    "        \n",
    "    \"\"\"update:学習\"\"\"\n",
    "    def update(self, data, mode=False, epoch=100):\n",
    "        # epoch=tqdm(epoch)\n",
    "        for e in range(epoch):\n",
    "            sum_log=0\n",
    "            # パラメータ計算\n",
    "            for batch, (X, y) in enumerate(data):\n",
    "                # 28*28を784次元に変換\n",
    "                # X=X.reshape(784)\n",
    "                # device調整\n",
    "                X=X.to(self.__device)\n",
    "                y=y.to(self.__device)\n",
    "                # 学習用データXをAutoEncoderモデルに入力 -> 計算結果 出力Y\n",
    "                pred_y=self.__model(X)\n",
    "\n",
    "                # 損失計算(ラベルYと予測Yとの交差エントロピーによる損失計算)\n",
    "                loss=self.__loss_func(pred_y, y)\n",
    "\n",
    "                # 誤差逆伝播を計算\n",
    "                # 勾配値を0にする\n",
    "                self.__opt.zero_grad()\n",
    "                # 逆伝播を計算\n",
    "                loss.backward()\n",
    "                # 勾配を計算\n",
    "                self.__opt.step()\n",
    "                \n",
    "                loss=loss.item()\n",
    "                sum_log+=loss\n",
    "            # 損失を格納\n",
    "            self.__loss_history.append(sum_log)\n",
    "            print(f'epoch:{e}, loss:{sum_log}')\n",
    "\n",
    "        # 損失保存\n",
    "        if mode:\n",
    "            \"\"\"汎用的な保存方法を検討中\"\"\"\n",
    "            # ファイル path\n",
    "            LOSS_SAVE=os.path.join(self.FILE_PATH, 'loss.txt')\n",
    "            # 損失結果 保存\n",
    "            np.savetxt(LOSS_SAVE, self.__loss_history)\n",
    "            # パラメータ保存\n",
    "            PARAM_SAVE=os.path.join(self.FILE_PATH, 'parameter.pth')\n",
    "            # 学習したパラメータを保存\n",
    "            torch.save(self.__model.state_dict(), PARAM_SAVE)\n",
    "        \n",
    "    \"\"\"test_accuracy:テストデータを使った精度評価\"\"\"\n",
    "    def test_accuracy(self, data, mode=False):\n",
    "        data=tqdm(data)\n",
    "        # 勾配なし\n",
    "        with torch.no_grad():\n",
    "            # 汎用的なデータセットに対応\n",
    "            n=0\n",
    "            # 精度\n",
    "            acc=0\n",
    "            # 精度\n",
    "            correct=0\n",
    "            # ラベル数の合計値\n",
    "            total=0\n",
    "            # パラメータ計算\n",
    "            for batch, (X, y) in enumerate(data):\n",
    "                # device調整\n",
    "                X=X.to(self.__device)\n",
    "                y=y.to(self.__device)\n",
    "                # 予測\n",
    "                pred=self.__model(X)\n",
    "                # 精度計算\n",
    "                correct+=(pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "                # 合計\n",
    "                total+=y.size(0)\n",
    "                # データ数 計算\n",
    "                n+=1\n",
    "            \n",
    "            # 精度[%]\n",
    "            acc=100*(correct/total)\n",
    "        \n",
    "        print(\"\\n ====================== \\n\")\n",
    "        print(f\"acc:{acc}\")\n",
    "        print(\"\\n ====================== \\n\")\n",
    "\n",
    "                # 損失保存\n",
    "        if mode:\n",
    "            \"\"\"汎用的な保存方法を検討中\"\"\"\n",
    "            # パラメータ保存\n",
    "            PARAM_SAVE=os.path.join(self.FILE_PATH, 'acc.txt')\n",
    "            # 学習したパラメータを保存\n",
    "            np.savetxt(PARAM_SAVE, [acc])\n",
    "\n",
    "        return acc\n",
    "    \n",
    "    \"\"\"prediction:予測\"\"\"\n",
    "    def prediction(self, X):\n",
    "        X=X.to(self.__device)\n",
    "        # 予測\n",
    "        pred=self.__model(X)\n",
    "        \n",
    "        print(\"\\n ====================== \\n\")\n",
    "        print(f\"y:{pred}\")\n",
    "        print(\"\\n ====================== \\n\")     \n",
    "\n",
    "        return pred\n",
    "    \n",
    "    \"\"\"features:特徴量抽出\"\"\"\n",
    "    def features(self, data):\n",
    "        x, y=data\n",
    "        x=x.to(self.__device)\n",
    "        x=self.__model.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alexnet import AlexNet\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# random seedを設定\n",
    "seed = 2023\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 実行文\n",
    "def main():\n",
    "    # 訓練データ\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "    print ('train_dataset = ', len(trainset))\n",
    "    \n",
    "    # データ\n",
    "    data=trainloader\n",
    "\n",
    "    # CNN\n",
    "    cnn=AlexNet()\n",
    "\n",
    "    # 学習\n",
    "    cnn.update(data, mode=True, epoch = 5)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
